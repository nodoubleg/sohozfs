<?xml version="1.0" encoding="utf-8"?>

<chapter xml:id="installation" xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0">
	<title>Installation</title>
	<para>
		In this chapter we will go through basic installation of ZFS modules in your Linux distribution of choice. Most popular distributions have some kind of easy installation support for ZFS. Ubuntu has PPA that allows for quick install and setup. 
	</para>
<sect1 xml:id="installation-1"><title>System packages</title>
	<para>
		Before going any further, we need to install some packages from standard distribution repositories.
	</para>
	<sect2 xml:id="installation-1-1"><title>Virtual Machine</title>
	<para>
		Before buying the hardware and running tests on bare metal, you may wish to install and test ZFS within a virtual machine. It is a good idea and I encourage you to do so. You may in a very simple and efficient way get used to administering ZFS pools. You may also check which distribution works better for you. There are no requirements to the virtualization engine. You can use VirtualBox, VMware, KVM, Xen or any other you feel comfortable with. Keep in mind, that the tool you use should be able to provide your guest machine with virtual disks to play with. While you can create pool on files created within the VM, I don't recommend that way of testing it.
		<note>
			Bear in mind that virtual machines are not suitable for performance testing. Too many factors will stand in the way of reliable results. 
		</note>
	</para>
	</sect2>
	<sect2 xml:id="installation-1-2"><title>Ubuntu Server</title>
		<para>
			If you are running Ubuntu prior to 15.10, you will need to add special PPA repository:
	<screen>
				<computeroutput>
	trochej@ubuntuzfs:~$</computeroutput> <userinput>sudo add-apt-repository ppa:zfs-native/stable</userinput>
<computeroutput>
	[sudo] password for trochej: 
	 The native ZFS filesystem for Linux. Install the ubuntu-zfs package.

	Please join this Launchpad user group if you want to show support for ZoL:

	  https://launchpad.net/~zfs-native-users

	Send feedback or requests for help to this email list:

	  http://list.zfsonlinux.org/mailman/listinfo/zfs-discuss

	Report bugs at:

	  https://github.com/zfsonlinux/zfs/issues  (for the driver itself)
	  https://github.com/zfsonlinux/pkg-zfs/issues (for the packaging)

	The ZoL project home page is:

	  http://zfsonlinux.org/
	 More info: https://launchpad.net/~zfs-native/+archive/ubuntu/stable
	Press [ENTER] to continue or ctrl-c to cancel adding it

	gpg: keyring `/tmp/tmp4_wvpmaf/secring.gpg' created
	gpg: keyring `/tmp/tmp4_wvpmaf/pubring.gpg' created
	gpg: requesting key F6B0FC61 from hkp server keyserver.ubuntu.com
	gpg: /tmp/tmp4_wvpmaf/trustdb.gpg: trustdb created
	gpg: key F6B0FC61: public key "Launchpad PPA for Native ZFS for Linux" imported
	gpg: Total number processed: 1
	gpg:               imported: 1  (RSA: 1)
	OK
</computeroutput>
		</screen>
		</para>
		<para>
			With Ubuntu 15.10 and later, zfs support packages are already within the standard repository. You will need to install the following packages:
			<screen>
				<computeroutput>
				trochej@ubuntuzfs:~$</computeroutput> <userinput>sudo apt-get install zfsutils-linux</userinput>
			</screen>
			That should install packages required to run zfs and compile appropriate kernel modules for you. You can later confirm they were built and in fact loaded by running <command>lsmod</command>:
			<screen>
	<computeroutput>trochej@ubuntuzfs:~$</computeroutput> <userinput>sudo lsmod | grep zfs</userinput>
	<computeroutput>
	zfs                  2252800  0
	zunicode              331776  1 zfs
	zcommon                53248  1 zfs
	znvpair                90112  2 zfs,zcommon
	spl                   102400  3 zfs,zcommon,znvpair
	zavl                   16384  1 zfs

				</computeroutput>
			</screen>
			You should be now able to create a pool:
			<screen>
				<computeroutput>
					trochej@ubuntuzfs:~$</computeroutput> <userinput>sudo zpool create -f datapool \
					mirror /dev/sdb /dev/sdc \
					mirror /dev/sdd /dev/sde \
					mirror /dev/sdf /dev/sdg</userinput>
	trochej@ubuntuzfs:~$ sudo zpool status
	  pool: datapool
	 state: ONLINE
	  scan: none requested
	config:

		NAME        STATE     READ WRITE CKSUM
		datapool    ONLINE       0     0     0
		  mirror-0  ONLINE       0     0     0
		    sdb     ONLINE       0     0     0
		    sdc     ONLINE       0     0     0
		  mirror-1  ONLINE       0     0     0
		    sdd     ONLINE       0     0     0
		    sde     ONLINE       0     0     0
		  mirror-2  ONLINE       0     0     0
		    sdf     ONLINE       0     0     0
		    sdg     ONLINE       0     0     0

	errors: No known data errors

			</screen>
		</para>
		<para>
			There is another package you will want installed: 
			<screen>
				rochej@ubuntuzfs:~$ sudo apt-get install zfs-zed
			</screen>
			<indexterm><primary>ZFS</primary><secondary>zed</secondary></indexterm>
			<literal>zed</literal> is a <literal>ZFS Event Daemon</literal>. It is a daemon service that will listen to any ZFS generated kernel event. It's explained in more detail in next section.
		</para>
	</sect2>
	<sect2 xml:id="installation-1-3"><title>CentOS</title>
		<para>
			You will need some system information tools, not installed by default, for monitoring, troubleshooting and testing of your setup:
			<screen>
	<computeroutput>
	[root@localhost ~]#</computeroutput><userinput> yum install sysstat</userinput>
			</screen>
		</para>
		<para>
			Contrary to Ubuntu, CentOS doesn't have ZFS packages by default in the repository neither in 6.7 nor 7 version. Thus you need to follow <ulink url="http://zfsonlinux.org/epel.html">ZFS On Linux EPEL</ulink> directions. I have CentOS 6.7 installed. The installation for CentOS 7 is exactly the same, except for package names:
			<screen>
				<computeroutput>
	[root@CentosZFS ~]# yum localinstall --nogpgcheck https://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
	[root@CentosZFS ~]# yum localinstall --nogpgcheck http://archive.zfsonlinux.org/epel/zfs-release.el6.noarch.rpm
	[root@CentosZFS ~]# yum install -y kernel-devel zfs
				</computeroutput>
			</screen>
			After some time you should be ready to probe and use zfs modules:
			<screen>
	[root@CentosZFS ~]# modprobe zfs
	[root@CentosZFS ~]# lsmod | grep zfs
	zfs                  2735595  0 
	zcommon                48128  1 zfs
	znvpair                80220  2 zfs,zcommon
	spl                    90378  3 zfs,zcommon,znvpair
	zavl                    7215  1 zfs
	zunicode              323046  1 zfs
			</screen>
		</para>
		You're now ready to create a pool on your attached disks:
		<screen>
	[root@CentosZFS ~]# zpool create -f datapool mirror /dev/sdb /dev/sdc mirror /dev/sdd /dev/sde
	[root@CentosZFS ~]# zpool status
	  pool: datapool
	 state: ONLINE
	  scan: none requested
	config:

		NAME        STATE     READ WRITE CKSUM
		datapool    ONLINE       0     0     0
		  mirror-0  ONLINE       0     0     0
		    sdb     ONLINE       0     0     0
		    sdc     ONLINE       0     0     0
		  mirror-1  ONLINE       0     0     0
		    sdd     ONLINE       0     0     0
		    sde     ONLINE       0     0     0

	errors: No known data errors

		</screen>
		The above installed aforementioned <literal>ZED</literal> for you.
	</sect2>
</sect1>
<sect1 xml:id="installation-2"><title>System tools</title>
	<para>
		You will need some system tools. Get used to them. 
		<itemizedlist>
			<listitem><para>We've already shown you <command>smartctl</command>. Read about this command. Not very critical, it may however provide interesting information on your disks' capabilities or their health.</para></listitem>
			<listitem><para><command>lsblk</command> will tell you what block devices you have. It will assist you in identifying drives' names you will use while setting u your ZFS pool.</para></listitem>
			<listitem><para><command>blkid</command> will help you identify drives already used by other filesystems. You may wish to use <command>mount</command> and <command>df</command> for that purpose too.</para></listitem>
</itemizedlist>
	</para>
</sect1>
<sect1 xml:id="installation-3"><title>ZED</title>
<indexterm><primary>ZFS</primary><secondary>zed</secondary></indexterm>
	<para>
		As mentioned previously, zed is a daemon that will listen to kernel events related to ZFS. Upon receiving it will conduct any action defined in so called ZEDLETs - a script or program that will carry on whatever action it's supposed to do. ZED is a Linux-specific daemon. In <literal>illumos</literal> distributions FMA is the layer responsible for carrying out corrective actions. 
	</para>
	<para>
		Writing ZEDLETs is a topic beyond this guide, but the daemon is essential for two important tasks: monitoring pool health and reporting it (via mail) and replacing failed drive with a hot spare. 
	</para>
	<para>
		Even though it is a ZFS that is responsible for marking drive as faulted, the replacement action needs to be carried out by a separate entity. 
	</para>
	<para>
		For those actions to work, after installing the daemon, open its configuration file, usually found in <literal>/etc/zfs/zed.d/zed.rc</literal>:
		<screen>
	# zed.rc

	# Absolute path to the debug output file.
	# ZED_DEBUG_LOG="/tmp/zed.debug.log"

	# Email address of the zpool administrator.
	#   Email will only be sent if ZED_EMAIL is defined.
	ZED_EMAIL="damian@wojslaw.pl"

	# Email verbosity.
	#   If set to 0, suppress email if the pool is healthy.
	#   If set to 1, send email regardless of pool health.
	#ZED_EMAIL_VERBOSE=0

	# Minimum number of seconds between emails sent for a similar event.
	#ZED_EMAIL_INTERVAL_SECS="3600"

	# Default directory for zed lock files.
	#ZED_LOCKDIR="/var/lock"

	# Default directory for zed state files.
	#ZED_RUNDIR="/var/run"

	# The syslog priority (eg, specified as a "facility.level" pair).
	ZED_SYSLOG_PRIORITY="daemon.notice"

	# The syslog tag for marking zed events.
	ZED_SYSLOG_TAG="zed"

	# Replace a device with a hot spare after N I/O errors are detected.
	#ZED_SPARE_ON_IO_ERRORS=1

	# Replace a device with a hot spare after N checksum errors are detected.
	#ZED_SPARE_ON_CHECKSUM_ERRORS=10

		</screen>

	Notice the <literal>ZED_EMAIL</literal>, <literal>ZED_SPARE_ON_IO_ERRORS</literal> and <literal>ZED_SPARE_ON_CHECKSUM_ERRORS</literal>. They are pretty self-explanatory. Uncomment them, if you want this functionality.
	</para>
	<para>
		The kernel messages that zed will listen to you can view using <command>zpool events</command> with or without <option>-v</option> switch. Without, you will receive a list similar to below:
		<screen>
	trochej@ubuntuzfs:~$ sudo zpool events   
	TIME                           CLASS
	Feb 15 2016 17:43:08.213103724 resource.fs.zfs.statechange
	Feb 15 2016 17:43:08.221103592 resource.fs.zfs.statechange
	Feb 15 2016 17:43:08.221103592 resource.fs.zfs.statechange
	Feb 15 2016 17:43:08.661096327 ereport.fs.zfs.config.sync
	Feb 15 2016 18:07:39.521832629 ereport.fs.zfs.zpool.destroy
		</screen>
		Those should be pretty obvious and in this case are directly related to creation, import and destruction of a pool.
	</para>
	<para>
		With the <option>-v</option> switch, output will be more verbose:
		<screen>
	trochej@ubuntuzfs:~$ sudo zpool events -v
	TIME                           CLASS
	Feb 15 2016 17:43:08.213103724 resource.fs.zfs.statechange
	        version = 0x0
	        class = "resource.fs.zfs.statechange"
	        pool_guid = 0xa5c256340cb6bcbc
	        pool_context = 0x0
	        vdev_guid = 0xba85b9116783d317
	        vdev_state = 0x7
	        time = 0x56c2001c 0xcb3b46c 
	        eid = 0xa

	Feb 15 2016 17:43:08.213103724 resource.fs.zfs.statechange
	        version = 0x0
	        class = "resource.fs.zfs.statechange"
	        pool_guid = 0xa5c256340cb6bcbc
	        pool_context = 0x0
	        vdev_guid = 0xbcb660041118eb95
	        vdev_state = 0x7
	        time = 0x56c2001c 0xcb3b46c 
	        eid = 0xb
		</screen>
	</para>
</sect1>
<sect1 xml:id="installation-9"><title>zfs-auto-snapshot</title>
	<para>
		One cool tool to install is ZFS Auto Snapshot: <ulink url="https://github.com/zfsonlinux/zfs-auto-snapshot">https://github.com/zfsonlinux/zfs-auto-snapshot</ulink>. I believe you should be able to follow the installation instructions from repository page. Configuration is pretty simple and consists of cron configuration files being added to your cron system service.
	</para>
</sect1>
<sect1 xml:id="installation-10"><title>arcstat.pl</title>
	<para>
		While it seems not to be a part of ZFS on Linux distribution after I installed packages, arcstat.pl will tell you important things, that will be covered later, in chapter <xref linkend="monitoring" />. Still, I consider this to be as important as other ZFS commands.
	</para>
	<para>
		You will need to start by cloning two github repositories from zfsonlinux project:
 		<screen>
  		<userinput>
	git clone https://github.com/zfsonlinux/linux-kstat.git

	git clone https://github.com/zfsonlinux/arcstat.git
 		</userinput>
 		</screen>
 		Next thing is to install their contents:
 		<screen>
  		<userinput>
	cd linux-kstat
	perl Makefile.PL
   	make
   	make test
   	sudo make install

   	cd ../arcstat
   	sudo mv arcstat.pl /sbin/
 		</userinput>
 		</screen>
 		As you can see, both are installed in a very simple and straightforward fashion. 
	</para>
</sect1>	
</chapter>
